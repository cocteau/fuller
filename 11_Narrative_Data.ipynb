{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "library(lubridate)\n",
    "library(stringr)\n",
    "library(lattice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\"Sometimes when my children were still little, my wife and I would stand over them as they lay sleeping in their beds. We spoke to each other only in silence, rehearsing a scene as old as mankind itself. It is as Ionesco told his journal: 'Not everything is unsayable in words, only the living truth.'\"\n",
    "<br><br>\n",
    "From *Computer Power and Human Reason: From Judgment To Calculation,* 1976, by Joseph Weizenbaum\n",
    "\n",
    "\n",
    "The narrative potential of data\n",
    "-------------------------------\n",
    "\n",
    "Today we are going to discuss the ways in which data are used to tell stories about the world. I will be less interested how you write around summary statistics or simple tabulations that you might insert in an article -- this is an important topic, of course, but our class has been working at a different level. Instead, I want to talk about the ways that technical framings, statistical models and their underlying assumptions, lead us to think about data and, in turn, suggest particular kinds of stories. \n",
    "\n",
    "So we are not talking about quoting a mean and standard deviation when we conclude that our data follow a bell curve, but instead we will see what happens when we ask \"Why do these data have a normal distribution?\" Connecting a model to data will produce stories -- from the structures of the models themselves to their mathematical origin stories. \n",
    "\n",
    "Before we get two far, I wanted to comment on one aspect of this enterprise. There different styles of working with models coming from different disciplines. Leo Breiman, a highly influential statistician who, among other things, pioneered the use of tree models, comments on this issue in a paper called [Statistical Modeling: The Two Cultures](http://www.stat.uchicago.edu/~lekheng/courses/191f09/breiman.pdf). He writes,\n",
    "\n",
    ">There are two cultures in the use of statistical modeling to\n",
    "reach conclusions from data. One assumes that the data are generated\n",
    "by a given stochastic data model. The other uses algorithmic models and\n",
    "treats the data mechanism as unknown. The statistical community has\n",
    "been committed to the almost exclusive use of data models. This commitment\n",
    "has led to irrelevant theory, questionable conclusions, and has kept\n",
    "statisticians from working on a large range of interesting current problems.\n",
    "Algorithmic modeling, both in theoryand practice, has developed\n",
    "rapidlyin fields outside statistics. It can be used both on large complex\n",
    "data sets and as a more accurate and informative alternative to data\n",
    "modeling on smaller data sets. If our goal as a field is to use data to\n",
    "solve problems, then we need to move awayfrom exclusive dependence\n",
    "on data models and adopt a more diverse set of tools.\n",
    "\n",
    "Today we are going to look at both forms of modeling as we move from the origins of statistics to artificial intelligence and machine learning. Let's see how this works 😌.\n",
    "\n",
    "**Shape**\n",
    "\n",
    "The most basic stories have to do with the shape of a distribution. Features that stand out force us to ask questions. For example, recall the distribution of the dates inmates were sentenced in the \"commutations\" data set we created. Just to remind you, we'll read it in, transform the string-based varible \"date\" into a date object with ymd() from \"lubridate\" and then have a look. [You can download a \"clean\" version here.](http://compute-cuj.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newcommutations = read.csv(\"comm3.csv\",as.is=TRUE)\n",
    "newcommutations = mutate(newcommutations,date=ymd(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=8, repr.plot.height=5)\n",
    "\n",
    "hist(newcommutations$date,breaks=50,main=\"Histogram of sentencing dates\",xlab=\"Date of original sentence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've mentioned, by adjusting the number of breaks in this display, we start to see features of the distribution. Here we almost see three modes -- one before 2000, one from 2000 to 2008 or so and then the small anomaly after 2013. Shape leads to stories as we ask ourselves \"Why?\" Sometimes the answers lead us to question the accuracy of the data itself, and other times we might hit on a useful observation about the world, the phenomenon we're observing. \n",
    "\n",
    "Asking \"Why?\" sometimes means we go back into the data. Other times we might take our pattern to someone more knowledgeable for advice. For example, we noted that inmates in Florida received the largest number of commutations. Perhaps state has something to do with this. \n",
    "\n",
    "We can use the \"faceting\" ability of lattice displays to examine if this is obviously the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top5 = c(\"illinois\",\"north carolina\",\"virginia\",\"texas\",\"florida\")\n",
    "histogram(~date|state,data=filter(newcommutations,state %in% top5),breaks=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at frequency displays of data has a long, long history. And certain shapes seem to come up often, so often that people have started to ask \"Why?\" at almost a meta-level. Mathematical analysis of why a distribution might occur in the first place gives rise to stories. The classic example of this is the so-called \"normal distribution.\"\n",
    "\n",
    "**Being normal**\n",
    "\n",
    "```                                 THE\n",
    "                                   NORMAL\n",
    "                                LAW OF ERROR\n",
    "                              STANDS OUT IN THE\n",
    "                            EXPERIENCE OF MANKIND\n",
    "                           AS ONE  OF THE BROADEST\n",
    "                          GENERALIZATIONS OF NATURAL\n",
    "                        PHILOSOPHY * IT SERVES AS THE\n",
    "                      GUIDING INSTRUMENT IN RESEARCHES\n",
    "                   IN THE PHYSICAL AND SOCIAL SCIENCES AND\n",
    "                  IN MEDICINE, AGRICULTURE AND ENGINEERING *\n",
    "             IT IS AN INDISPENSABLE TOOL FOR THE ANALYSIS AND THE\n",
    "      INTERPRETATION OF THE BASIC DATA OBTAINED BY OBSERVATION AND EXPERIMENT\n",
    "```\n",
    "\n",
    "This comes from William Youden, a chemist, statistician and, evidently, amateur typographer. It's hard to undersell the influence that the normal distribution has had in statistics. Even its naming is somewhat remarkable.\n",
    "\n",
    ">In science, multiple discoveries have been found to be the rule (Merton, 1973, p. 356), but multiple independent appearances of the same terminology for the same scientific object must surely be the exception. Yet this is exactly what happened with the appearance of the word \"normal\" as a descriptive of the probability curve\n",
    "<br><br>\n",
    "$$\\phi(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}$$\n",
    "<br>\n",
    "by Charles S. Pierce (1873), by Francis Galton (1877) and by Wilhelm Lexis (1977). Such multiplicity of naming - in three countries and two languages- is remarkable and surely signals a widespread simultaneously evolving conceptual understaining in the 1970s: of popualtions of people, of measurements and of their similarities.\n",
    "\n",
    "The normal distribution, as a statistical model, has a long history. It was invoked as the \"error\" distribution, due to a technical result (the Central Limit Theorem) that says (essentially) if you add up a number of small mistakes, the resulting distribution for errors looks bell-shaped. The best example I can think of to explain this is Galton's Quincunx Machine. It's like a late 1800s version of a pachinko machine. \n",
    "\n",
    "<img src=\"http://www.statisticalconsultants.co.nz/weeklyfeatures/WF32/Galton-box-commentary.jpg\" width=300>\n",
    "\n",
    "Everytime a ball hits one of the pins it falls to the left or the right with equal probability, 0.5. Small errors, if you will, adding up to give you something that looks like a bell curve. This is the Central Limit Theorem. \n",
    "\n",
    "You try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the number of pins balls will encounter on the\n",
    "# way down through the machine\n",
    "\n",
    "height = 50\n",
    "\n",
    "# specify how many balls you want to drop\n",
    "balls = rep(0,1000)\n",
    "\n",
    "for(i in 1:1000){\n",
    "    \n",
    "    # sample a +1 or -1 with equal probability for each pin\n",
    "    leftright = sample(c(-1,1),height,replace=TRUE)\n",
    "    \n",
    "    # sum up the +1 and -1 to get the ball's final location\n",
    "    balls[i] = sum(leftright)\n",
    "}\n",
    "\n",
    "# plot it!\n",
    "hist(simulation,breaks=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normal stories**\n",
    "\n",
    "In the early 1800s Adolphe Quetelet spent much of his career reasoning from the normal distribution, applying it to a range of social data. Quetelet is considered a founder of the social sciences — He was a \"tireless promoter of statistical data collection\" with one of his main analytical tools being the normal distribution (the Gaussian distribution or the bell curve).\n",
    "\n",
    ">After graduation with a doctorate from the University of Gent, Quetelet was] recruited to teach mathematics at the Athenée in Brussels... and on a trip to Paris he met Joseph Fourier (1768–1830), Siméon Poisson (1781–1840) and Pierre Laplace (1749–1827), became impassioned by the subject of probability, and went on to put it to practical use in the study of the human body, a subject in which he had developed an early interest as a painter and sculptor. In doing so, he became the first to develop height and weight tables to study their relationships, and a pioneer in the application of mathematical analysis to the study of man...<br><br>\n",
    "Quetelet's interest in the subject was kindled when on his return from Paris, he got involved in a national population census of the Netherlands and argued that a random sample from a representative diversified group could be used to estimate the total population. His subsequent conceptual evolution in the study of man evolved from the study of averages (physical characteristics), to rates (birth, marriage, growth) and ultimately distributions (around an average, over time, between regions and countries). The latter was the basis of one of his contributions to statistics; **the demonstration that the normal Gaussian distribution, typical throughout nature, applied equally to physical attributes of humans, including body parts, derived from large-scale population studies.** After that, he saw bell-shaped curves everywhere he looked, including in social phenomena and the variables that determine character and aptitudes...\n",
    "<br><br>\n",
    "Adolphe Quetelet (1796–1874) [*The average man and indices of obesity*](http://ndt.oxfordjournals.org/content/23/1/47.full)\n",
    "\n",
    "Quetelet made extensive use of the bell curve in his work. He saw that it described the distribution of physical characteristics (not to mention “moral” characteristics) of people in the various data sets he examined. But his understanding of the normal came from astronomy where it was applied as an error distribution. Here's his own drawing.\n",
    "\n",
    "<img src=\"http://www.infovis.info/visuals/Gallery_of_Data_Visualization/Historical_Milestones/1800+/symm_hist_binomial_quetelet_1846.jpg\" width=500>\n",
    "\n",
    "Quetelet saw stability in official statistics — This kind of stability felt law like to him, making an analogy with the laws of physics. He saw this in births and deaths and marriages, in the ratio of boys to girls born, and even in the crime rate. \n",
    "\n",
    "<img src=\"https://archive.org/services/img/b21987257\">\n",
    "\n",
    "(Cut to slides)\n",
    "\n",
    "**L’homme Moyen**\n",
    "\n",
    "That the bell curve was used as a kind of error distribution is important because it frames how Quetelet interprets the statistical work he’s done -- Noticing that human physical and “moral” characteristics have bell-shaped distributions led him to a very particular interpretation of the mean.\n",
    "\n",
    "In short, Quetelet interprets the average as a kind of ideal or a state of perfection.\n",
    "\n",
    ">It is a statistical conception of the universe possessing qualities of poetic and artistic beauty. Everything is to be viewed as varying about a normal state in a manner to be accurately described by beautiful bell-shaped curves of perfect symmetry but of varying amplitude. Thus it is that the individual varies about his normal self; thus members of a group vary about their average; thus the men of a nation, viewed as individuals, vary about the average man of the nation; thus a nation varies about its normal state; and finally, inasmuch as the qualities of the average man change from time to time and place to place in obedience to general causes, to follow the course of the average man in the whole series of nations would give us, in Quetelet’s view, the principles of a social physics, the true mechanics of human history.\n",
    "<br><br>\n",
    "*Adolphe Quetelet as Statistician*, by Frank Hamilton Hankins\n",
    "\n",
    "Here is a larger discussion from Ted Porter, a historian who studies statistics and quantification more broadly.\n",
    "\n",
    ">**It’s been said that around 1830 there was a paradigm shift from the enlightened or rational man to the average man. Could you elaborate a little on the history of the term “the average man” and what is at stake in this shift—from the man of reason to man as quantifiable and subject to quantification?**\n",
    "<br><br>\n",
    "The enlightened man was also quantifiable, in fact was more obviously quantifiable, than the average man, because enlightenment meant rationality, and rational decisions should reflect a kind of mathematical ordering. The rise of statistics in the early 19th century attests to a loss of faith in the power of individual reason, or at least to a new anxiety about the masses. The average man embodied a form of political activity that could no longer be understood as the rationality of probabilistic calculation. In place of individualistic rationality, the age of mass society gave us a collective order of statistical averages. The term “average man” was invented by the Belgian Adolphe Quetelet in the 1830s to support his new quantitative science, a science of the whole population. The average was a way of embracing the whole of society and of giving it an individualized representation. Quetelet’s idea was to found a science of society on the basis of this emblematic figure of the average man, which was taken as typical or representative.\n",
    "<br><br>\n",
    "**But Quetelet often refers to the average man as a fiction, as a construction. How does “the average man” relate to the life of the living individual?**\n",
    "<br><br>\n",
    "It is a fiction in the sense that no real person will have all the characteristics of the average man. In some ways you might think of the average man as the basis for a quantitative model, a person whom the ambitious social scientist uses to abstract away from concrete individuality. This was a fiction anchored in reality, and Quetelet even argued that statistics could help novelists and poets delineate characters who would be appropriate for their age. And there are ways in which he made the average man more real than actual, flesh-and-blood human beings. He portrayed the average man as the center of the symmetrical distribution that we know as the normal or bell curve. For Quetelet, this role was comparable to that of an average in the physical science of astronomy. Here the average stands for the true value of something that you’re trying to measure, and the spread of measures around the mean is just a distribution of errors. From the standpoint of science, the statistical, emblematic figure of the average man more closely represents society as a whole than any flesh-and-blood individual ever can. Quetelet’s average, though fictional, becomes more real than the actual people who make up the distribution.\n",
    "<br><br>\n",
    "**Is the average man the ideal? Should one aspire to be average?**\n",
    "<br><br>\n",
    "It’s an interesting question because now we tend to see the average as mediocre rather than exemplary. Quetelet wasn’t totally unaware of this aspect. Yet there are a couple of ways he managed to idealize the average man nonetheless. One was by celebrating the stability of the average. While any individual will have highs and lows, being sometimes desperately in love, sometimes obsessed with philosophy or poetry or natural science, wavering perhaps between radicalism and conservatism in politics, the average smoothes over these fluctuations and is therefore more stable. Quetelet was acutely conscious of living in a revolutionary age, not just in the wake of the French Revolution of 1789, but as one who saw his scientific ambitions gravely threatened by the Belgian Revolution in 1830. One reason for idealizing the average is just its stability, its equanimity and its calmness, when the world is raging with passion. A second perspective, which he drew from Aristotle, is to see extremes as vice and the average as virtuous balance. Instead of thinking of a continuum from low ability to high ability, he imagined a spectrum, say, of passion or of politics, where both extremes are dangerous and the average means stability, the foundation of steady progress. I would say, finally, that Quetelet’s average man fits into a system of social teleology, representing not any concrete production of nature, but nature’s intention.\n",
    "<br><br>\n",
    "*Life on the Bell Curve: An Interview with Theodore Porter*\n",
    "￼￼http://www.cabinetmagazine.org/issues/15/fleming2.php\n",
    "\n",
    "Quetelet creates the notion of L'homme Moyen, the average man. This gentleman is the center of the bell curve -- Here he applies the reasoning to physical characteristics, but he reasoned similarly with a range of “moral” data as well.\n",
    "\n",
    ">Suppose... that one wished to make a thousand copies of a statue, say the Gladiator. Like astronomical observations of a single object, these copies would be subject to a variety of errors -- in measuring the various dimensions, in workmanship and so on. The independent errors are like terms of a binomial, and combine in a characteristic fashion. Hence the variation among the copies would be governed by a profound regularity, the error law or normal curve, with the dimensions of the original Gladiator at the mean. But this is an impossible experiment.<br><br>\n",
    "How did Quetelet know what the result would be? “I shall perhaps astonish you very much by stating that the experiment has been already made. Yes, surely, more than a thousand copies have been measured of a statue, which I do not assert to be that of the Gladiator, but which in all cases differences little from it. These copies were living ones... \" (1846, p. 136)\n",
    "<br><br>from *The Empire of Chance*\n",
    "\n",
    "Here are Quetelet's data. The data came from the Edinburgh Medical and Surgical Journal from 1817. \n",
    "\n",
    "<img src=\"http://www.medicine.mcgill.ca/epidemiology/hanley/bios601/DescriptiveStatistics/chest_scottish_soldiers.gif\" width=400>\n",
    "\n",
    "Of these data, Stephen Stigler, a historian of statistics, writes\n",
    ">The original data consisted of separate tables of measurements for the members of eleven different local militia, cross-classified by height and chest circumphrence. None of the eleven tables gave marginal totals for the chest measurements, hence Quetelet would have to do quite a bit of summing to get his data. A careful recomputation of the totals shows that there were actually 5,732 soldiers.  The data were collected by an army contractor, preumably charged with clothing the various militia... It is interesting that Quetelet ignored the entire cross-classification, as it is just the kind of table that in a different intellectual climate might have suggested a bivariate normal distribution.\n",
    "\n",
    "[Download the Scottish data set here](http://compute-cuj.org/chests.csv) and then let's have a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chest = read.csv(\"chests.csv\")\n",
    "head(chest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim(chest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist(chest$size,main=\"Histogram of chest sizes\",xlab=\"size (in inches)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=5, repr.plot.height=5)\n",
    "\n",
    "qqnorm(chest$size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking of variation through errors, Quetelet considered the average man as a kind of ideal -- He wrote \"an individual who epitomized in himself, at a given time, all the qualities of the average man, would represent at once all the greatness, beauty and goodness of that being.\" In a recent piece in The Atlantic, [How the Idea of a ‘Normal’ Person Got Invented](http://www.theatlantic.com/business/archive/2016/02/the-invention-of-the-normal-person/463365/), Todd Rose writes,\n",
    "\n",
    ">Quetelet’s invention of the Average Man marked the moment when the average became normal, the individual became error, and stereotypes were validated with the imprint of science. These assumptions would eventually prompt generations of parents to worry if their child did not develop according to the average milestones, and cause almost everyone to feel anxiety when their health, social life, or career deviated too far from the average.\n",
    "\n",
    "Before we leave Quetelet, there is a connection to criminology. The first annual crime statistics were published in France in 1827. In [one historical account](http://law.jrank.org/pages/909/Criminology-Intellectual-History-Positivist-criminology.html#ixzz4Ry5rNkQQ) we read \n",
    "\n",
    ">One of the first people to analyze these statistics was Adolphe Quetelet (1796–1874). He found that some people were more likely to commit crime than others, especially those who were young, male, poor, unemployed, and undereducated. Young males were more likely to commit crime under any circumstances, so that places with more young males tended to have more crime. But places with more poverty and more unemployment actually had less crime. As it turned out, the poor and unemployed tended to commit crimes in places where there were many wealthy and employed people. Quetelet suggested that opportunities might have something to do with explaining this pattern. **He also pointed to an additional factor: the great inequality between wealth and poverty in the same place excites passions and provokes temptations of all kinds. This problem is especially severe in those places where rapidly changing economic conditions can result in a person suddenly passing from wealth to poverty while all around him still enjoy wealth.** In contrast, provinces that were generally poor had less crime as long as people were able to satisfy their basic needs. Quetelet found that people with more education tended to commit less crime on the whole but they also tended to commit more violent crime. He therefore argued that increased education itself would not reduce crime.\n",
    "\n",
    "This gave rise to the first crime maps. Michael Friendly has a fantastic [summary of these maps](http://projecteuclid.org/download/pdfview_1/euclid.ss/1199285037) and the difficulty of making sense of multivariable data.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/c/c6/AMGuerry-carte1-low.jpg\" >\n",
    "\n",
    "\n",
    "**More normal than normal**\n",
    "\n",
    ">One feature of many naturally occurring or engineered complex systems is tremendous variability in event sizes. To account for it, the behavior of these systems is often de- scribed using power law relationships or scaling distribu- tions, which tend to be viewed as \"exotic\" because of their unusual properties (e.g., infinite moments). An alternate view is based on mathematical, statistical, and data-analytic arguments and suggests that scaling distributions should be viewed as \"more normal than Normal.\"\n",
    "<br><br>*More 'Normal' than Normal: Scaling Distributions and Complex Systems* by Willinger, Alderson, Doyle, and Li\n",
    "\n",
    "In recent years, so-called heavy-tail distributions have been examined mathematically in search of plausible origin stories, the answer to \"Why?\" Heavy-tail distributions have appeared in the news, with Malcom Gladwell writing about \"hockey-stick distributions\" and Clay Shirky commenting on the Pareto distribution. \n",
    "\n",
    "Take the Pareto in which, quoting a [Newsweek story](http://www.newsweek.com/get-smarter-66995),\n",
    "\n",
    ">the richest or busiest or most connected participants in a system will account for much much more wealth, or activity, or connectedness than average. The top 1 percent of a population owns 40 percent of the wealth; the top 2 percent of Twitter users send 60 percent of all tweets; medical care for the most expensive one fifth of patients accounts for four fifths of total spending. 'These figures are always reported as shocking,' notes Shirky, as if anything but a nice bell curve were an aberration, but Pareto distributions pop up all over. Regarding them as anomalies 'prevents us from thinking clearly about the world,' he argues, and from finding ways to, say, reduce income disparities.\"\n",
    "\n",
    "\n",
    "\n",
    "[Read more here.](http://users.cms.caltech.edu/~adamw/papers/2013-SIGMETRICS-heavytails.pdf) Now, to have a look at a data set of this kind, [download some data from an experiment at the NYTimes](http://compute-cuj.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visits = read.csv(\"nyt.csv\",as.is=TRUE)\n",
    "sample_n(visits,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim(visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary(visits$VisitLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=8, repr.plot.height=5)\n",
    "\n",
    "hist(visits$VisitLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist(visits$VisitLength,breaks=1000,xlim=c(0,2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformations**\n",
    "\n",
    "This is a technical aside, but the use of transformations can help us represent the data on the right scale. Some scales like currency or weight are linear, others are logarithmic. The Richter scale for earth quakes is on a log (base 10 in this case) scale so that an earthquake measuring 5.0 has an amplitude 10 times greater than an earthquake registering 4.0. \n",
    "\n",
    "Again, the mathematics of certain distributions suggest different kinds of transformations. Poisson distributions are often used for counts. There, the natural transformation is a square root. When your data are sampled from a binomial, the arc-sin-squareroot transform is recommended.\n",
    "\n",
    "In the early 1960s Box and Cox addressed scaling in one go with their transformation<br><br>\n",
    "$$\\frac{x^\\lambda-1}{\\lambda}$$\n",
    "<br>where $\\lambda$ is just a positive constant. We are looking for something that tucks large values in so $\\lambda<1$ makes sense. Here's a plot. Play with it a little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x represents the range of our data, just the numbers 1 to 500\n",
    "x = 1:500\n",
    "\n",
    "# try a value of lambda and make a plot\n",
    "lambda = 1/2\n",
    "y = (x^lambda-1)/lambda\n",
    "plot(x,y,type=\"l\",col=\"yellow\")\n",
    "\n",
    "# add another, smaller value of lambda. what happens?\n",
    "lambda = 1/5\n",
    "y = (x^lambda-1)/lambda\n",
    "lines(x,y,col=\"green\")\n",
    "\n",
    "lambda = 1/10\n",
    "y = (x^lambda-1)/lambda\n",
    "lines(x,y,col=\"blue\")\n",
    "\n",
    "# finally, add the logarithm. where is it in relation to the others?\n",
    "y = log(x)\n",
    "lines(x,y,col=\"red\")\n",
    "\n",
    "# add the line y=x (no transformation) to the plot\n",
    "lines(x,x,lty=2,col=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, try another strategy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try another strategy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kind of scaling is often introduced implicitly without having to mention logarithms or any word like that. For example, when Google Analytics provides you with a barchart of \"time spent\" on the site, they break things down into categories.\n",
    "\n",
    "Tell me about them.\n",
    "\n",
    "<img src=\"http://www.analytics-ninja.com/wordpress/wp-content/uploads/2015/02/hidden-browser-tab-distribution.png\" width=500>\n",
    "\n",
    "**The other culture**\n",
    "\n",
    "As we said, in many cases, we don't care about \"Why?\", we just want to know that we can predict with reasonable accuracy. This is the spirit of many machine learning algorithms. They tend to be opaque, black boxes if you will, and difficult to interrogate. We'll see examples shortly. Here is an example having to do with distributional shape. It comes from an older telecommunication system, the Telegraph. \n",
    "\n",
    "We've all heard the dee-dee-dee-dee tapping of Morse code, in television or movies, presumably. The characteristic dots and dashes assign letters and numbers to patterns or codewords. Given a message, an operator would \"encode\" the message into dots and dashes using the \"codebook\". These patterns were then communicated over the telegraph and another operator used the codebook to \"decode\" the message.\n",
    "\n",
    "In creating a codebook to map letters onto dots and dashes, what properties might be desirable? Have a look at Morse code and see if anything comes to mind.\n",
    "\n",
    "<img src=\"http://study.com/cimages/multimages/16/morse_code.jpg\">\n",
    "\n",
    "The idea, which Claude Shannon formalized, is that if you can associate the length of a codeword (the number of dots and dashes, here) with the frequency of a letter (frequent items get short code words), your messages will involve less effort to transmit. In short, the better you can describe a model for the source of your letters, the shorter your messages.\n",
    "\n",
    "Now, it's 1830 or so, how do you decide what the word frequency is for common english? \n",
    ">In November an December 1837, when Vail built the instruments, he visited Louis Vogt, proprietor of a print shop in Morristown, and, over a case of type, learned which letters of the alphabet were used most frequently. He assigned the fewest dots and dashes to those letters\"\n",
    "\n",
    "We can try this ourselves. Download [a seasonal text from Project Gutenberg.](http://www.gutenberg.org/cache/epub/46/pg46.txt). Download it to where you started your notebook. I sent it to Downloads. Then, we use \"stringr\" to join all the lines into 1 big string and get rid of all the non-word characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = readLines(\"Downloads/pg46.txt\")\n",
    "d = str_replace_all(str_c(d,collapse=\"\"),\"\\\\W\",\"\")\n",
    "str_sub(d,1,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, reduce them to lowercase and split them into separate letters. table() and sort() the result. What do you see? Compare this to the pattersn in Morse code. Consistent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letters = str_split(tolower(d),\"\")[[1]]\n",
    "head(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sort(table(letters),decreasing=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machines**\n",
    "\n",
    "1. Rules vs. \"learning\"\n",
    "2. Regression\n",
    "3. Decision trees\n",
    "4. Regression, logistic regression, neural networks\n",
    "5. Cyberjournalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "http://www.mugu.com/galton/essays/1880-1889/galton-1886-jaigi-regression-stature.pdf"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
