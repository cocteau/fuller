{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R basics and clustering\n",
    "----------\n",
    "\n",
    "Today we are going to look at a powerful narrative generator in data analysis, clustering. Often, we find that data suggest natural groups of people or places or objects or events based on our measurements. Clusters can be as simple as bumps or **\"modes\" in a histogram of a single variable** (think about the two modes we observed when we looked at a histogram of the percentage change in violent crimes from 2015 to 2016 for 62 cities -- roughly we had a group that experienced a drop in crime and those that experienced an increase), to **groups that involve more variables at once** (today we'll look at violent crimes across 41 years in our 62 cities -- 62 curves displaying violent crime as a function of time -- and find groups of cities that have similar curves). \n",
    "\n",
    "There are a number of different procedures or \"algorithms\" for putting data into groups (figuring out which cities look more like each other than the rest of the data set based on crime statistics, say). We will look at one procedure that is particularly simple, albeit with an intimidating name: **hierarchical clustering.** \n",
    "\n",
    "**Table Manipulations via dplyr**\n",
    "\n",
    "Before we get there, however, I want to spend a little more time with some basic table operations in R. Working with tabular data is extremely common -- think about all the calculations you've made with a spreadsheet program. Last time we saw how to extract data from collections of rows and columns, how to create new columns, and how to compute simple summary statistics. Those operations involved the \"$\" sign, the use of square brackets \\[  \\], and basic functions like sum() and mean() and median. \n",
    "\n",
    "Today we'll look at a **package** that makes it easier to **create new tables from old**.\n",
    "\n",
    "A package is simply a bundle of code and data. By authoring packages, people can contribute new functionality to the R language. In the case we will look at today, the package was written by [Hadley Wickham](http://hadley.nz/), and introduces new functions to make table manipulations a little simpler. The package is called **dplyr.**\n",
    "\n",
    "Last time, we saw how important it was to perform simple numerical calculations on tables. Today we are going to perform some of the same operations, but using functions from dplyr. To learn about a package, we can read the documentation provided by its author. [Here is the documentation for dplyr](https://cran.r-project.org/web/packages/dplyr/index.html). It can be a little opaque. Sometimes, however, when people create a package in R, they also write a **vignette** that walks you through how to use the data and commands in the package. That is true for dplyr, and you can read the [vignette for dplyr](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html) after we've run through this brief introduction. \n",
    "\n",
    "Here are the new commands -- or \"verbs\" -- Hadley has introduced with his package. We'll show how to use them in the examples below. In each case, **the functions take a table (a data frame) as input and return another, altered data frame as output.** These functions let you specify subsets, sort on columns, and create new columns. But in each case, you give a table and you get a table.\n",
    "\n",
    "- filter()\n",
    "- arrange()\n",
    "- select()\n",
    "- distinct()\n",
    "- mutate()\n",
    "- summarise()\n",
    "- group_by()\n",
    "- sample_n()\n",
    "\n",
    "We will again use the FBI Uniform Crime Reporting statitics, and start by reading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucr = read.csv(\"ucr_crime_1975_2015.csv\",as.is=TRUE)\n",
    "head(ucr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we make use of the new package authored by Hadley. We call the command library() with the name of the package. The R web site publishes [a list of all the packages that are available for you](https://cran.r-project.org/web/packages/available_packages_by_name.html).  We'll talk about packages in a little detail a bit later in the semester. For now, let's just use dplyr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might get a message (colored pinkish) warning you that Hadley has chosen a name for some of his functions that are already being used by R. For example, the name \"filter\" was given to a function that the original designers of R created -- it has to do with \"filtering\" curves like our crime plot of Miami. Hadley chose to give a function in dplyr the same name, \"filter\", creating a conflict between what the R creators developed and what Hadley contributed in dplyr. We now have two functions named \"filter.\" \n",
    "\n",
    "The pink warning message is telling you how R has resolved the conflict -- the name \"filter\" will now refer to Hadley's function rather than the original version. This kind of warning is usually not something we'll worry about, but I wanted you to understand why there's suddenly a pink box in your notebook.\n",
    "\n",
    "Instead of dealing with \"time series\" of data like the original \"filter\" function, the dplyr version filters a data frame in the sense that it selects only rows containing certain conditions -- it creates \"subsets\" of our original data table. In our case, we're going to use dplyr to find subsets of the crime data occurring in certain years or in certain places. For example, l\n",
    "\n",
    "\n",
    "et's start by using Hadley's **filter()** command to create a subset of the UCR data for Miami. The command takes a data set and then one or more conditions. It returns a data set consisting of rows that satisfying the conditions you specify. \n",
    "\n",
    "Here are some examples. First, pull out the 41 data points in our UCR table that refer to Miami. The \"==\" sign is a logical operator that selects just those department_name's that are equal to \"Miami\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(ucr, department_name == \"Miami\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With filter() we provide the name of the data set and then one or more conditions separated by commas. Below we look at just the data from Miami for 1982."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(ucr,department_name == 'Miami', year==1982)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we formed subsets last time, we had to use square brackets and the \"$\" sign to specify which variables, or columns, we were using to create our subsets. This is a bit more readable. Oh and here \"department_name\" and \"year\" are automatically interpreted as data columns coming from the dataset ucr. \n",
    "\n",
    "This is why the dplyr tools are popular. See how easy it is to read what we're doing? Below we look for all the data for Miami between 2001 and 2015. We see two operators, \"less than or equal\" and  \"greater than or equal\" that we use to specify the range of years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(ucr,department_name == 'Miami', year <= 2015, year >= 2001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several operators for making comparisons. Here are a few.\n",
    "\n",
    "- <  less than\n",
    "- \\>  greater than\n",
    "- <=  less than or equal to\n",
    "- \\>=  greater than or equal to\n",
    "- ==  equal to\n",
    "\n",
    "One last handy operator is %in%. This allows you to specify options rather than a range as we did with \"<=\" and \"\\>=\". We might specify the options we're after using the concatenate function c(). In the code below we look for a department_name that is \"Miami\" or \"Boston\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(ucr,department_name %in% c(\"Miami\",\"Boston\"), year==2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a few subsets of your own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the crime data for Los Angeles\n",
    "# Put your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the crime data for Atlanta in our data set for 1975 and 2015 \n",
    "# Put your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find 2015 crime data for cities that are bigger than Miami in 2015\n",
    "# Put your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find entries in our table where the violent crime per 100,000 people is larger than 4,000\n",
    "# Put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command filter() returns a data frame (remember that's R's table). In the past few expressions we have bee letting the subsets of data just print to the notebook. We can catch the data and give it a name also. Here's how we make a data set for Miami, using the name \"miami\". (It's often good practice to name your data descriptively -- calling Miami's crime statistics \"philly\" would just be  confusing.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "miami = filter(ucr, department_name == 'Miami')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next verb we'll look at from Hadley is **select()**. This chooses columns to keep in a data set. So rather than consider all the data, we might select certain variables. Here we look at just \"year\" and \"total_pop\" for Miami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select(miami,year,total_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the result is a data frame, another table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select two different columns from your miami data set\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The verb **arrange()** sorts data based on the values in one or more columns. It reorders rows as you would in a spreadsheet if you chose to sort the sheet by a column (or two or three). Here we create a data set of big cities (populations larger than 1.5M) and sort them by population..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = filter(ucr, year==2015, total_pop > 1500000)\n",
    "arrange(cities,total_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and if we wanted cities ordered so that population is descending rather than ascending we use desc()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrange(cities,desc(total_pop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the next commands we create a data set of big cities (populations larger than 3M) for any year and sort the resulting data by department_name and then year. That means, when we have data from the same city, we order them by year. We can add as many column names as we like in arrange() and it will continue to break ties while it sorts using the columns deeper in the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = filter(ucr, total_pop > 3000000)\n",
    "arrange(cities,department_name,year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The verb **summarise()**(Hadley is from New Zealand) creates simple summary statistics. Here you supply the columns you'd like to summarize and what you'd like to name the summaries. The function will create a new data labeling the columns with the names you provide. Summary functions like sum(), mean(), median(), var() for variance, sd() for standard deviation, min() and max() are just some of the things you can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miami = filter(ucr, department_name == 'Miami')\n",
    "summarise(miami,homicide=sum(homs_sum), robbery=sum(rob_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summarise() function really comes in handy when paired with **group_by()**. This function forms groups of rows of your data set depending on vaues of the variable you specify. Below we group data by department_name. We then summarise() the data in each group, creating a new table where each row contains the summaries for a given city. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = group_by(ucr,department_name)\n",
    "summarise(cities,homicide=sum(homs_sum), robbery=sum(rob_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a data set, one row per city, consisting of largest and smallest  \n",
    "# rates of violent crime per 100K people over the 1975-2015 period. Call the columns\n",
    "# maxv and minv\n",
    "#\n",
    "# Put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the command **mutate()** creates new columns in your data set. Last time we did it with \"$\", but here the function takes the name of the data set and then one or more expressions defining new columns. Here we divide violent_crime by total_pop to get a \"per person\" or per capita figure (rather than per 100K people). The new column is called \"violent_percapita\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ucr = mutate(ucr,violent_percapita=violent_crime/total_pop)\n",
    "head(new_ucr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you see the new column all the way to the right of the table.\n",
    "\n",
    "**Back to our crime analysis and clustering -- to be done on Tuesday in class**\n",
    "\n",
    "Let's load up another data set. It can be downloaded from Courseworks or from [this link.](https://www.dropbox.com/s/3qmxqg7vri1ja8c/new_ucr.csv?dl=0) It contains information in our original data, but organized differently. Can you see what happened? How is this data set diferent from our original?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucr = read.csv(\"new_ucr.csv\",row.names=1)\n",
    "head(nucr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the difference here. What computations are suddenly easier in this form and what's harder?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This form makes simple plots across years very easy to express. Here are histograms of violent crimes per 100K people in 1990 and 2015. Notice the ranges are quite different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=7,repr.plot.height=6)\n",
    "\n",
    "hist(nucr$y1990,main=\"1990 Violent Crimes\",xlab=\"Violent crimes per 100K people\")\n",
    "hist(nucr$y2015,main=\"2015 Violent Crimes\",xlab=\"Violent crimes per 100K people\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the way we extract data from a table using \"$\". While dplyr takes old tables and makes new tables, our lessons from last week allow us to extract the data from a table and feed it to a histogram or some other display or summary. \n",
    "\n",
    "Functions like hist() want a \"vector\" of data points (the data from a column or row in a table, say) and not a table. A vector in R is simply a collection of values. They might be numeric or characters (names of things) or boolean (TRUE/FALSE). You can create one by subsetting a table..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nucr$y1990"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or by using the concatenate command c(). Here we make a vector of six numbers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c(1,3,12,3,4,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and here six cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c(\"Boston\",\"Atlanta\",\"Los Angeles\",\"New York\",\"Chicago\",\"Seattle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combine our two lessons, we can use dplyr functions to create new data sets in a clean (readable) way and then make a histogram of what we've created by extracting data from the table. So here we look at relative differences in violent crimes from 1990 to 2015 and 2010 to 2015. In the Marshall Project article, the former is Obama's view of crime and the latter is Trump's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = mutate(nucr,long=(y2015-y1990)/y1990,short=(y2015-y2010)/y2010)\n",
    "\n",
    "hist(drops$long,main=\"Relative drops between 1990 and 2015\",xlab=\"Percent change\")\n",
    "hist(drops$short,main=\"Relative drops between 2010 and 2015\",xlab=\"Percent change\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time, we made use of the plot() command to create simple scatterplots and time series plots of our crime statistics. To overlay the data from many cities at once, we can use a command called matplot(), which is short for \"matrix plot.\"\n",
    "\n",
    "Here we supply a common x-axis (here the years 1975 through 2015) and a table of columns, where each column is to be plotted against the same x-axis. In the code below, our columns are, well, rows of nucr. That is, we take the transpose, t(), of nucr so that the columns are cities and the rows are years. We then create our plot. \n",
    "\n",
    "This is a very specialized plot so don't worry too much about t() and matplot(). The result is what we're after -- to look at all the years for the different cities at one time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is what t() does...\n",
    "head(nucr)\n",
    "head(t(nucr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplot(1975:2015,t(nucr),type=\"l\",lty=1,col='grey',xlab=\"year\",ylab=\"Violent Crime per 100K residents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for our clustering, we want to identify groups of cities. Notice from the plot above, for example, that we have a number of cities with really low crime rates. Their curves are all grouped together visually. The top four or five curves also have basically the same shape and are near each other visually.\n",
    "\n",
    "Clustering is a way to create groups of cities that have similar crime characteristics. Clustering often begins with a notion of **distance** between two rows in a data set. Clusters are then defined as groups of points that are closer to each other than to the rest of the data set. \n",
    "\n",
    "The curves above are good examples to start with because we can see each row of data as a curve. That's the reason we went to the new data format! When two curves near each other, the distance should be small. For distance, we'll just use the sum of squared differences between curve values, across time. \n",
    "\n",
    "That's a mouthful so here's a closeup, the distance between Atlanta and Boston. First extract the rows of data we need as vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nucr[\"Atlanta\",]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = nucr[\"Boston\",]\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and here is the distance. We take differences between a and b, square them, sum them up and then take a square root. Remember your geometry! Below we make the calculation and also unpack it in pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(sum((a-b)^2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a-b)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((a-b)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R has a function that will compute the distances between all pairs of rows in a data set. It's called, poetically enough, **dist()**. Here we make a small data set of three rows and compute the 3 pairs of distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small = nucr[c(\"Atlanta\",\"Boston\",\"Houston\"),]\n",
    "small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist(small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do this for the entire data set of 61 cities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dist(nucr)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical clustering forms groups of cities, rows in our data set. It does so by progressively joining the nearest data points and organizes them into a tree. We went over this in class but [here is a short YouTube video from Jeff Leek](https://www.youtube.com/watch?v=nIsLDtXlalo) that explains the process nicely.\n",
    "\n",
    "Here how we fit the clustering tree. The magic of this procedure is how you compare two groups of points using their pairwise distances. We'll talk about this more later, but for now, there's a guy with the last name of Ward and he created a technique that tries to form really tight clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit = hclust(d,method=\"ward.D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and how we define k=4 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=8,repr.plot.height=6)\n",
    "plot(fit,cex=0.8)\n",
    "rect.hclust(fit,k=4,border=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a vector of 61 values (one for each city) that tells us the different groups defined by the clustering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutree(fit,k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look at the different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = cutree(fit,k=4)\n",
    "matplot(1975:2015,t(nucr[groups==1,]),type=\"l\",lty=1,col='grey',xlab=\"year\",ylab=\"Violent Crime per 100K residents\",ylim=c(0,4400))\n",
    "matplot(1975:2015,t(nucr[groups==2,]),type=\"l\",lty=1,col='grey',xlab=\"year\",ylab=\"Violent Crime per 100K residents\",ylim=c(0,4400))\n",
    "matplot(1975:2015,t(nucr[groups==3,]),type=\"l\",lty=1,col='grey',xlab=\"year\",ylab=\"Violent Crime per 100K residents\",ylim=c(0,4400))\n",
    "matplot(1975:2015,t(nucr[groups==4,]),type=\"l\",lty=1,col='grey',xlab=\"year\",ylab=\"Violent Crime per 100K residents\",ylim=c(0,4400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the data group roughly from low values to high. But the shapes look about right. From here we can dig in and explain what these cities have in common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The complete set of cities**\n",
    "\n",
    "Now, we have been provided a much larger group of cities. I'd like to have you make some observations about the data. We are no longer dealing with a handful of cities, but the  set of UCR agencies with complete records from 1975-2014 -- roughly 13,000. The data were retrieved from [the NACJD](https://www.icpsr.umich.edu/icpsrweb/content/NACJD/guides/ucr.html). You can pull it from [this link](https://www.dropbox.com/s/qim69g8k3ehrmsc/all_ucrs75-14.csv?dl=0) or you can get it from Courseworks. It will take a little while to load, but then you should start to ask some questions -- What do the columns mean? (The NACJD site I linked to has a data dictionary.) What questions might you have about trends other than our 61 cities? Kick the tires on your simple subsetting and summary statistics. \n",
    "\n",
    "Come up with 5 basic questions and either answer them or try to and we will address them in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ucr = read.csv(\"all_ucrs75-14.csv\",as.is=TRUE)\n",
    "head(all_ucr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code for your 5 questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
